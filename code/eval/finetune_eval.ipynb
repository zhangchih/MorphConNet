{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import yaml\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from models.pointnetv2_encoder import PointNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"../config/config.yaml\", \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of all data is 1726\n"
     ]
    }
   ],
   "source": [
    "# from data_utils.ModelNetDataLoader import ModelNetDataLoader\n",
    "# train_dataset = ModelNetDataLoader('/data/nerdxie/neuron_cluster/neuron_dataset_1',split='train', uniform=True, normal_channel=True,istrain=False,)\n",
    "# test_dataset = ModelNetDataLoader('/data/nerdxie/neuron_cluster/neuron_dataset_1',split='test', uniform=True, normal_channel=True,istrain=False,)\n",
    "from data_utils.TestDataLoader import FAFBDataset\n",
    "# full_dataset = ModelNetDataLoader('./data_neuron.h5', uniform=True, normal_channel=True, istrain=False)\n",
    "full_dataset = FAFBDataset('../../fafb-cellseg', uniform=True, normal_channel=True, catfile='classname_3c.txt')\n",
    "\n",
    "labelname = ['neurite', 'glia', 'soma']\n",
    "\n",
    "train_size = int(0.5 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1024, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape:\", train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=4, drop_last=True, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(batch_size/2),\n",
    "                          num_workers=4, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "encoder = PointNetV2(**config['network']).to(device)\n",
    "# encoder.projetion = torch.nn.Sequential()\n",
    "encoder = torch.nn.DataParallel(encoder).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained parameters\n",
    "load_params = torch.load(os.path.join('../pre-trained/model_sslcontrast.pth'),\n",
    "                         map_location=torch.device(torch.device(device)))\n",
    "\n",
    "# for i in load_params['online_network_state_dict'].keys():\n",
    "#     if 'projetion' in i:\n",
    "#         del load_params['online_network_state_dict'][i]\n",
    "\n",
    "if 'online_network_state_dict' in load_params:\n",
    "    encoder.load_state_dict(load_params['online_network_state_dict'])\n",
    "    print(\"Parameters successfully loaded.\")\n",
    "\n",
    "# remove the projection head\n",
    "# encoder = torch.nn.Sequential(*list(encoder.cpu().children())[:-1])    \n",
    "# encoder = encoder.to(device)\n",
    "# output_feature_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(1024, 3)\n",
    "logreg = logreg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_encoder(encoder, loader):\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # get the features from the pre-trained model\n",
    "    for batch, y, index in loader:\n",
    "        batch = batch.to(device)\n",
    "        features = encoder(batch)[1]\n",
    "        x_train.extend(features)\n",
    "        y_train.extend(y.numpy())\n",
    "\n",
    "            \n",
    "    x_train = torch.stack(x_train)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "optimizer = torch.optim.Adam(params=chain(logreg.parameters(), encoder.parameters()), lr=7e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "eval_every_n_epochs = 2\n",
    "\n",
    "best_acc = 0\n",
    "soma_acc = 0\n",
    "neurite_acc = 0\n",
    "glia_acc = 0\n",
    "eval_every_n_epochs = 1\n",
    "best_val = 0\n",
    "val_acc = 0\n",
    "test_acc = 0\n",
    "best_epoch = 0\n",
    "best_acc = 0\n",
    "\n",
    "true_name = []\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "for epoch in range(200):\n",
    "#     train_acc = []\n",
    "    print('Starting Training Epoch {}'.format(epoch))\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch, y, _ in train_loader:\n",
    "        encoder.train()\n",
    "        logreg.train()\n",
    "        batch = batch.to(device)\n",
    "        features = encoder(batch)[1]\n",
    "        logits = logreg(features)\n",
    "        y = y.to(device).squeeze(1).long()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() \n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        total += y.size(0)\n",
    "        correct += (predictions == y).sum().item()\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Training accuracy: {np.mean(train_acc)}\")\n",
    "#     if epoch == 9:\n",
    "#         optimizer = torch.optim.Adam(params=chain(logreg.parameters(), encoder.parameters()), lr=3e-5)\n",
    "    total = 0\n",
    "    if epoch % eval_every_n_epochs == 0:\n",
    "        encoder.eval()\n",
    "        logreg.eval()\n",
    "        true_name = []\n",
    "        best_val = val_acc\n",
    "        correct_soma = 0\n",
    "        correct_neurite = 0\n",
    "        correct_glia = 0\n",
    "        total_soma = 0\n",
    "        total_neurite = 0\n",
    "        total_glia = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x, y, _ in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).squeeze(0).long()\n",
    "            y = y.squeeze(1)\n",
    "            # print(y.shape)\n",
    "            x = encoder(x)[1]\n",
    "\n",
    "            logits = logreg(x)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "            total += y.size(0)\n",
    "            total_neurite += (predictions == 0).sum().item()\n",
    "            total_glia += (predictions == 1).sum().item()\n",
    "            total_soma += (predictions == 2).sum().item()\n",
    "            y = y.cpu().numpy()\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            true_sample = y[np.where(predictions == y)]\n",
    "            correct_neurite += (true_sample == 0).sum()\n",
    "            correct_glia += (true_sample == 1).sum()      \n",
    "            correct_soma += (true_sample == 2).sum()\n",
    "            correct += len(true_sample)\n",
    "#                 true_name.extend(name[np.where(predictions == y)])\n",
    "\n",
    "        test_acc = np.mean(100 * correct / total)\n",
    "        best_acc = max(test_acc, best_acc)\n",
    "        if best_acc == test_acc:\n",
    "            torch.save(logreg.state_dict(), 'save_model/linear.pt')\n",
    "            torch.save(encoder.state_dict(), 'save_model/encoder.pt')\n",
    "            print(f'saving best finetuned model at epoch: {epoch}')\n",
    "        soma_acc = correct_soma / total_soma\n",
    "        glia_acc = correct_glia / total_glia\n",
    "        neurite_acc = correct_neurite / total_neurite\n",
    "        best_epoch = epoch\n",
    "\n",
    "    print(f\"Current Val Accuracy: {val_acc}, Current Test Accuracy: {test_acc} on Epoch {best_epoch}. Soma {soma_acc} Neurite {neurite_acc} Glia {glia_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}