{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import yaml\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from models.pointnetv2_encoder import PointNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"../config/config.yaml\", \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- True\n",
      "The size of train data is 668782\n"
     ]
    }
   ],
   "source": [
    "# from data_utils.ModelNetDataLoader import ModelNetDataLoader\n",
    "# train_dataset = ModelNetDataLoader('/data/nerdxie/neuron_cluster/neuron_dataset_1',split='train', uniform=True, normal_channel=True,istrain=False,)\n",
    "# test_dataset = ModelNetDataLoader('/data/nerdxie/neuron_cluster/neuron_dataset_1',split='test', uniform=True, normal_channel=True,istrain=False,)\n",
    "from data_utils.FAFBAnalysisDataLoader import TestDataLoader\n",
    "# full_dataset = ModelNetDataLoader('./data_neuron.h5', uniform=True, normal_channel=True, istrain=False)\n",
    "test_dataset = TestDataLoader('/data/nerdxie/neuron_cluster/neuron_dataset_add_all_128/',split='train', uniform=True, normal_channel=True,istrain=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                          num_workers=4, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "encoder = PointNetV2(**config['network']).to(device)\n",
    "# encoder.projetion = torch.nn.Sequential()\n",
    "encoder = torch.nn.DataParallel(encoder).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained parameters\n",
    "\n",
    "# for i in load_params['online_network_state_dict'].keys():\n",
    "#     if 'projetion' in i:\n",
    "#         del load_params['online_network_state_dict'][i]\n",
    "\n",
    "encoder.load_state_dict(torch.load(os.path.join('encoder2.pt'),\n",
    "                         map_location=torch.device(torch.device(device))))\n",
    "print(\"Parameters successfully loaded.\")\n",
    "\n",
    "# remove the projection head\n",
    "# encoder = torch.nn.Sequential(*list(encoder.cpu().children())[:-1])    \n",
    "# encoder = encoder.to(device)\n",
    "# output_feature_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "logreg = LogisticRegression(1024, 3)\n",
    "logreg = logreg.to(device)\n",
    "logreg.load_state_dict(torch.load(\"linear2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_encoder(encoder, loader):\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    names = []\n",
    "\n",
    "    # get the features from the pre-trained model\n",
    "    for batch, y, index in loader:\n",
    "        index = [int(i) for i in index]\n",
    "        with torch.no_grad():\n",
    "            batch = batch.to(device)\n",
    "            features = encoder(batch)[1]\n",
    "            x_train.extend(features)\n",
    "            y_train.extend(y.numpy())\n",
    "            names.extend(index)\n",
    "\n",
    "            \n",
    "    x_train = torch.stack(x_train)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    names = torch.tensor(names)\n",
    "    return x_train, y_train, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7373261686,\n",
      "\n",
      "6728294998,\n",
      "\n",
      "4773759577,\n",
      "\n",
      "5152613609,\n",
      "\n",
      "1364923236,\n",
      "\n",
      "7123331250,\n",
      "\n",
      "3339227829,\n",
      "\n",
      "3476793718,\n",
      "\n",
      "4854978392,\n",
      "\n",
      "5239341559,\n",
      "\n",
      "7786366204,\n",
      "\n",
      "9038233181,\n",
      "\n",
      "9966795344,\n",
      "\n",
      "7007222160,\n",
      "\n",
      "3594623136,\n",
      "\n",
      "5007297358,\n",
      "\n",
      "6833507315,\n",
      "\n",
      "7102001756,\n",
      "\n",
      "9728463636,\n",
      "\n",
      "5575718128,\n",
      "\n",
      "3312459596,\n",
      "\n",
      "5537111588,\n",
      "\n",
      "8115709146,\n",
      "\n",
      "7219284669,\n",
      "\n",
      "3048185702,\n",
      "\n",
      "11668962620,\n",
      "\n",
      "3945788599,\n",
      "\n",
      "10122552546,\n",
      "\n",
      "9593485909,\n",
      "\n",
      "6316222667,\n",
      "\n",
      "9596019497,\n",
      "\n",
      "7902560961,\n",
      "\n",
      "1889518298,\n",
      "\n",
      "1511523325,\n",
      "\n",
      "7886967662,\n",
      "\n",
      "9590526182,\n",
      "\n",
      "5668514759,\n",
      "\n",
      "9590460255,\n",
      "\n",
      "11163690782,\n",
      "\n",
      "5004796152,\n",
      "\n",
      "8169935449,\n",
      "\n",
      "9702933988,\n",
      "\n",
      "7258364614,\n",
      "\n",
      "2279222153,\n",
      "\n",
      "4856802544,\n",
      "\n",
      "11429012371,\n",
      "\n",
      "6087899674,\n",
      "\n",
      "8404141761,\n",
      "\n",
      "6340375788,\n",
      "\n",
      "7062710568,\n",
      "\n",
      "10634710896,\n",
      "\n",
      "5137571488,\n",
      "\n",
      "5579319116,\n",
      "\n",
      "5251453421,\n",
      "\n",
      "5048149262,\n",
      "\n",
      "2026537380,\n",
      "\n",
      "7753230466,\n",
      "\n",
      "6366433664,\n",
      "\n",
      "6192030877,\n",
      "\n",
      "1993267566,\n",
      "\n",
      "5402532419,\n",
      "\n",
      "7007456071,\n",
      "\n",
      "3984958787,\n",
      "\n",
      "8147757316,\n",
      "\n",
      "4097605359,\n",
      "\n",
      "9607258826,\n",
      "\n",
      "4984684651,\n",
      "\n",
      "7014547076,\n",
      "\n",
      "8409556950,\n",
      "\n",
      "1743004132,\n",
      "\n",
      "1496097455,\n",
      "\n",
      "4658070385,\n",
      "\n",
      "12196788978,\n",
      "\n",
      "3717968191,\n",
      "\n",
      "4489018209,\n",
      "\n",
      "2942043617,\n",
      "\n",
      "9727816917,\n",
      "\n",
      "12099617372,\n",
      "\n",
      "2009898312,\n",
      "\n",
      "1741852081,\n",
      "\n",
      "11571039435,\n",
      "\n",
      "8144989506,\n",
      "\n",
      "2677216808,\n",
      "\n",
      "6744562015,\n",
      "\n",
      "7134412689,\n",
      "\n",
      "8553197857,\n",
      "\n",
      "6344733800,\n",
      "\n",
      "5817046569,\n",
      "\n",
      "11705524385,\n",
      "\n",
      "2280490027,\n",
      "\n",
      "5408320754,\n",
      "\n",
      "7615051973,\n",
      "\n",
      "4882990433,\n",
      "\n",
      "3693088468,\n",
      "\n",
      "8150558870,\n",
      "\n",
      "11023349473,\n",
      "\n",
      "10780881874,\n",
      "\n",
      "6090402708,\n",
      "\n",
      "6696944306,\n",
      "\n",
      "6437254116,\n",
      "\n",
      "12881421674,\n",
      "\n",
      "6722857355,\n",
      "\n",
      "2787760936,\n",
      "\n",
      "6735630918,\n",
      "\n",
      "9083101040,\n",
      "\n",
      "6974911485,\n",
      "\n",
      "7004052204,\n",
      "\n",
      "4630563746,\n",
      "\n",
      "1744920244,\n",
      "\n",
      "12748989380,\n",
      "\n",
      "5044716138,\n",
      "\n",
      "5018224368,\n",
      "\n",
      "5454138599,\n",
      "\n",
      "11677897997,\n",
      "\n",
      "4220264621,\n",
      "\n",
      "4481804455,\n",
      "\n",
      "6073112403,\n",
      "\n",
      "3940093304,\n",
      "\n",
      "8014515915,\n",
      "\n",
      "9321921881,\n",
      "\n",
      "5411443384,\n",
      "\n",
      "8786146552,\n",
      "\n",
      "7892031694,\n",
      "\n",
      "12064301235,\n",
      "\n",
      "11422672263,\n",
      "\n",
      "2005406442,\n",
      "\n",
      "5142338096,\n",
      "\n",
      "7625727635,\n",
      "\n",
      "8827685718,\n",
      "\n",
      "6867823885,\n",
      "\n",
      "1899152130,\n",
      "\n",
      "3969506090,\n",
      "\n",
      "9217591841,\n",
      "\n",
      "7615966580,\n",
      "\n",
      "1863934375,\n",
      "\n",
      "7373473740,\n",
      "\n",
      "8688206222,\n",
      "\n",
      "6042828983,\n",
      "\n",
      "5527490634,\n",
      "\n",
      "10764976110,\n",
      "\n",
      "11809650915,\n",
      "\n",
      "2039967253,\n",
      "\n",
      "7242765788,\n",
      "\n",
      "6237209991,\n",
      "\n",
      "3307298635,\n",
      "\n",
      "8033050347,\n",
      "\n",
      "5282493060,\n",
      "\n",
      "9584873639,\n",
      "\n",
      "6485900374,\n",
      "\n",
      "7788356803,\n",
      "\n",
      "9859390635,\n",
      "\n",
      "11407295792,\n",
      "\n",
      "7386876841,\n",
      "\n",
      "6967238960,\n",
      "\n",
      "8944527422,\n",
      "\n",
      "7098380091,\n",
      "\n",
      "6311705444,\n",
      "\n",
      "8024872218,\n",
      "\n",
      "6621095492,\n",
      "\n",
      "11440665504,\n",
      "\n",
      "4645149095,\n",
      "\n",
      "8136071759,\n",
      "\n",
      "6049415297,\n",
      "\n",
      "6486448629,\n",
      "\n",
      "5944231624,\n",
      "\n",
      "5948095689,\n",
      "\n",
      "8048730450,\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9a6bddd2a001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# print(logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "logreg.eval()\n",
    "encoder.eval()\n",
    "pre = []\n",
    "t_file = '/code/PyTorch-BYOL/eval/predicted_glia_original_data.txt'\n",
    "t = open(t_file, \"w\")\n",
    "names = []\n",
    "for batch, y, index in test_loader:\n",
    "    index = [int(i) for i in index]\n",
    "    with torch.no_grad():\n",
    "        batch = batch.to(device)\n",
    "        features = encoder(batch)[1]\n",
    "        logits = logreg(features)\n",
    "        # print(logits)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        # print(predictions)\n",
    "        pre.extend(predictions)\n",
    "        names.extend(index)\n",
    "        glias = np.where(predictions.cpu() == 1)\n",
    "        for glia in glias[0]:\n",
    "            t.write(str(index[glia])+',\\n')\n",
    "            print(str(index[glia])+',\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6, 9]),)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
